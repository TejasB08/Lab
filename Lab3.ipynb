{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNTLxT7Udcf4UYQ0O5GY8FF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2tvKp-cU55A3","executionInfo":{"status":"ok","timestamp":1763569075594,"user_tz":-330,"elapsed":28652,"user":{"displayName":"Tej","userId":"02638544543032583857"}},"outputId":"39f3eac0-9fbb-4520-df90-103867920649"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 Loss: 0.4760\n","Epoch 2 Loss: 0.3133\n","Epoch 3 Loss: 0.2161\n","Epoch 4 Loss: 0.1642\n","Epoch 5 Loss: 0.1371\n","Test Accuracy: 0.9\n"]}],"source":["import tensorflow as tf\n","from sklearn.datasets import make_classification\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","# Create dataset\n","X, y = make_classification(n_samples=1000, n_features=20, n_classes=2)\n","# Convert to numpy arrays before splitting\n","X_np = X.astype('float32')\n","y_np = y.reshape(-1, 1).astype('float32')\n","\n","\n","# Split\n","x_train_np, x_test_np, y_train_np, y_test_np = train_test_split(X_np, y_np, test_size=0.2)\n","\n","# Convert back to TensorFlow tensors after splitting\n","x_train = tf.convert_to_tensor(x_train_np, dtype=tf.float32)\n","x_test = tf.convert_to_tensor(x_test_np, dtype=tf.float32)\n","y_train = tf.convert_to_tensor(y_train_np, dtype=tf.float32)\n","y_test = tf.convert_to_tensor(y_test_np, dtype=tf.float32)\n","\n","\n","# Define model\n","class MLP(tf.keras.Model):\n","    def __init__(self):\n","        super().__init__()\n","        self.d1 = tf.keras.layers.Dense(64, activation='relu')\n","        self.d2 = tf.keras.layers.Dense(32, activation='relu')\n","        self.out = tf.keras.layers.Dense(1, activation='sigmoid')\n","\n","    def call(self, x):\n","        x = self.d1(x)\n","        x = self.d2(x)\n","        return self.out(x)\n","\n","# Instantiate model\n","model = MLP()\n","loss_fn = tf.keras.losses.BinaryCrossentropy()\n","optimizer = tf.keras.optimizers.Adam()\n","\n","# Training loop (batch + manual)\n","batch_size = 32\n","for epoch in range(5):\n","    for i in range(0, len(x_train), batch_size):\n","        x_batch = x_train[i:i+batch_size]\n","        y_batch = y_train[i:i+batch_size]\n","        with tf.GradientTape() as tape:\n","            logits = model(x_batch)\n","            loss = loss_fn(y_batch, logits)\n","        grads = tape.gradient(loss, model.trainable_variables)\n","        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n","    print(f\"Epoch {epoch+1} Loss: {loss.numpy():.4f}\")\n","\n","# Evaluate\n","preds = tf.round(model(x_test))\n","accuracy = tf.reduce_mean(tf.cast(tf.equal(preds, y_test), tf.float32))\n","print(\"Test Accuracy:\", accuracy.numpy())"]}]}